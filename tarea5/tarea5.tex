\documentclass{article}

\usepackage[utf8x]{inputenc}
\usepackage[spanish]{babel}
\usepackage[margin=3cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{ upgreek }

\usepackage{listings}

\linespread{1.2}

\title{ Computación Concurrente \\ \Large{Tarea 5}
\author{
  Diego Goméz Montesinos
  \and
  José Emiliano Cabrera Blancas
  }
\date{11 marzo 2014}
}
\begin{document}
\maketitle
\begin{enumerate}
  
\item{
    \textsl{
      Recuerden la platica de Borzoo sobre \textit{program
        repair}. Encuentra un algoritmo polinomial que repare la
      secuencia de estados, en el caso de una sola condición de
      progreso $\square$ (P $\Rightarrow$ $\triangle$Q), en donde hay
      un ciclo y sólo puedes quitar transiciones. Demuestra que es
      correcto y que es polinomial.\\
    }
 
    El algoritmo que Borzoo desarrolla es una heurística que abarca
    una clase de programas, esto es por que se sabe que el problema más
    general es NP-Completo. La entrada del algoritmo es la siguiente,
    la transicion de un programa con predicado $T_p$, un predicado
    invariante $I_p$, un conjunto de transiciones fallidas $F$ y un
    predicado de transicion malo $SPEC_{bt}$ y la salida a este
    algorítmo es un programa de transiciones con predicado $T_{p'}$
    con su predicado invariante $I_{p'}$.\\
    
\begin{lstlisting}[frame=single,mathescape,numbers=left,emph={repeat,until,return},emphstyle=\textbf]
ms := BWReachStates(Guard(F $\wedge$ $SPEC_{bt}$), F)
$I_{1}$, fte := $I_p$ - ms, false
mt := ($\langle$ms$\rangle$' $\vee$ $SPEC_{bt}$) $\wedge$ Group($\neg$ms)
repeat
   $I_2$ := $I_1$
   repeat
      $S_1$, $T_2$ := $I_1$, $T_1$
      repeat
         $S_2$ := $S_1$
         $S_1$ := FWReachStates($I_1$, $T_1$ $\vee$ F)
         $S_1$ := $S_1$ - fte
         mt := mt $\wedge$ $S_1$
         $T_1$ := $T_1$ - Group($T_1$ $\wedge$ mt)
      until ($S_1$ = $S_2$)
      ds := $S_1$ $\wedge$ $\neg$Guard($T_1$)
      $T_1$ := $T_1$ $\vee$ AddRecovery(ds,$I_1$, $S_1$, mt)
      ds := $S_1$ $\wedge$ $\neg$Guard($T_1$)
      $T_1$, fte :=  Eliminate(ds,$T_1$,$I_1$,$S_1$,$F$,false,false)
   until ($T_1$ = $T_2$)
   $T_1$, $I_1$ := ConstructInvariant($T_1$,$I_1$,fte)
until ($T_1$,$I_2$)
$I_{p'}$,$T_{p'}$ := $I_1$, $T_1$
return $I_{p'},$ $T_{p'}$
\end{lstlisting}

En la primera línea utilizamos la función $BWReachStates$ como una
caja negra(esta función fue tratada en otro trabajo y podemos decir
que su tiempo de procesamiento es polinomial), $BWReachStates$ sirve 
para obtener un $state$ $predicate$ donde las fallas por si solas
incurren en una violación al
predicado, de forma más explicita $Guard(F \wedge SPEC_{bt})$ son los
estados en donde directamente las fallas violan el $safety$ $predicate$
y la caja negra explora solamente hacia atrás buscando transiciones 
fallidas($FWReachStates$ funciona de forma parecida, buscando hacia
adelante en lugar de hacia atrás).\\
En la línea dos, como ya obtuvimos un predicado que nos obtiene estados
malos, entonces procedemos a retirar $ms$ para que nuestro programa de
salida sea tolerante a los fallos que hasta el momento hemos encontrado.\\
En la línea tres calculamos la variable $mt$ que son los predicados
que el programa que queremos hacer tolerante a fallos no debe ejecutar.\\
El primer $loop$ sirve para recalcular el predicado invariante, el
segundo sirve para recalcular el predicado de transición y el tercer y
último $loop$ recalcula el $fault$ $span$.\\
Necesitamos recalcular el $fault$ $span$ en cada iteración del segundo
$loop$ por que nuestro algoritmo añade y remueve transiciones que
originan los $fault$ $span$, por lo que nuevos estamos podrían ser
alcanzados y otros inalcanzables.\\
Es importante tener en claro que recalculamos el $fault$ $span$
comenzado una exploracion de los estados donde la invariante $I_1$ es
verdadera y aplicando las transiciones del predicado en la repesencia
de fallas(i.e $T_1$ $\wedge$ $F$) usando la funcion $FWReachStates$,
que previamente ya se habia comentado, $fte$ contiene las transiciones
malas previamente calculadas, por lo que procedemos a removerlas de
$S_1$.
Debemos notar que una condicion necesaria para que una transicion sea
no segura, es que su transicion origen sea un $fault$ $span$, en otro
caso la transicion puede existir en el predicado del programa tolerante
a fallos incluso si este se encuentre dentro de $SPEC_{bt}$ (linea 12).\\
Una vez que identificamos las transiciones no seguras, las quitamos
del predicado del programa (linea 13).\\
Ahora que hemos removido algunas transiciones se puede dar el caso en
donde se generen $deadlock$ que podemos componer de dos formas,
añadiendo un camino para recuperar la ejecucion del programa o
eliminando transiciones para que el $deadlock$ sea inalcanzable para
el programa. Estas dos operaciones se llevan acabo en las funciones
$AddRecovery$ y $Eliminate$.\\
La explicación de forma intuitva de como implementar $AddRecovery$ es
la siguiente: una vez detectado el $deadlock$ procedemos a crear una
nueva transicion que conecte el $deadlock$ con las transiciones
validas, si esta transición crea un ciclo en los estados, entonces no
se añade y se vuelve a buscar otra transicion que sea posible. Para
implemetar la busqueda de posibles ciclos nuevos, el autor Borzoo
incorpora el enfoque de Emerson y Lei.\\
El procedimiento para eliminar nuevos estados es, primero si ya todos
los estados $deadlock$ en $ds$ ya fueron considerados para eliminarse,
entonces $Elminate$ regresa los estados $deadlock$. Por otro lado si la
transición es alcanzable por una transicion fallida, entonces
regresamos al estado fuente del predicado y lo hacemos
inalcanzable. Esto es por que el programa no tiene ningun control
sobre cuando las fallas puede ocurrir.\\ 
Durante el proceso de eliminar los $deadlocks$ nos encontramos con que
algunas de esas transiciones pueden tener conflico con el predicado
invariate, marcando estas transiciones como $OffendingStates$.\\
Después de eliminar los $deadlocks$ procedemos a recalcular la
invariante con la función $ConstructInvariant$, esta funcion tiene
como proposito remover los estados del conjunto $OffendingStates$ del
predicado invariante y hacer esos estados inalcanzables.\\
Por último repitimos otra vez todos los pasos anteriores descritos hasta
terminar con la ejecución del programa.\\

El tiempo de ejecición claramente es polinomial puesto que en la
descripcion anterior vamos describiendo pasos que son polinomiales y
se repiten un numero polinomial de pasos.\\
El algoritmo es correcto, por que en cada paso nos vamos asegurando de
no agregar nuevas transiciones que lleven al programa aun
$deadlock$. Y vamos agregando nuevas transiciones cuando hay fallas
nuevas.



  }

  \item{
      \textsl{
        Explicar por qué el proble de encontrar un ciclo que pase por
        2 vértices dados es NP-Completo. (Solo dar un esbozo de la
        prueba)
      }
    }

  \item{
      \textsl{
        Recordemos ahora el modelo de memoría compartida wait-free y
        asíncrono para n procesos. El algoritmo que ejecutan los
        procesos en primera instancia fue:
      }
      \begin{lstlisting}[frame=single,mathescape]
Alg (id):
        r := -1
        view := id
   loop:
        r  := r+1
        mem[r] := write(view)
        $\upchi$ := scan(mem[r])
        view := conjunto de id's en $\upchi$
   until | view | = n-r
   output view
      \end{lstlisting}
      \textsl{
        Después vimos una modificación al algoritmo, en el cual un
        proceso ''no olvida'' si en una iteración anterior vio a algún
        otro proceso. Cambiamos el código de la siguiente manera:
      }
\begin{lstlisting}[frame=single,mathescape]
AlgNoOlvida (id):
        r := -1
        view := id
   loop:
        r  := r+1
        mem[r] := write(view)
        $\upchi$ := scan(mem[r])
        view := view $\cup$ id's en $\upchi$
   until | view | >= n-r
   output view
      \end{lstlisting}
      \textsl{
        Demuestra que los dos algoritmos son correctos y que cumplen
        la propiedad de que las vistas de los procesos están
        contenidas de acuerdo al orden en que los procesos terminan su
        iteración. (i.e. el proceso j terminó después que el proceso
        k, entonces la vista del proceso j esta contenida en la vista
        del proceso k.)
      }
    }

  \item{
      \textsl{
        Hagan un resumen de la plática sobre consenso de no más de 2
        páginas de la platica de Michel Raynal.
      }

      \textbf{PROBLEMA DEL CONSENSO PARA SISTEMAS SÍNCRONOS}\\
      Primero vimos el modelo síncrono de secuencia de rondas.
      En este modelo tenemos lo siguiente:
      \begin{itemize}
        \item Un conjunto $\Uppi$ de n procesos $\{p_{1}, p_{2}, ..., p_{n}\}$
        \item Una red de comunicación confiable.
        \item Una ejecución consiste en una recuencia de rondas.
        \item Una variable global $r$ que será el número de ronda
        \item Cada proceso $p_{i}$ es informado cada vez que $r$ incrementa.
      \end{itemize}
      Cada ronda está hecha de tres fases consecutivas: Fase de envío, Fase de recibo y fase de procesamiento.
      En este modelo tenemos una propiedad fundamental (de sincronía) que es:\\
      " Un mensaje $m$ enviado por un proceso $p_{i}$ a un proceso $p_{j}$ en la ronda
      $r$, es recibido por $p_{j}$ en la misma ronda $r$".\\
      Ahora, que pasa si consideramos errorres o fallas en los procesos.\\
      En el modelo de fallos en los procesos podemos considerar estas cosas:
      \begin{itemize}
        \item Proceso defectuoso. Es aquel que se desvía de su algoritmo.
        \item Proceso correcto. Es aquel que nunca se desvía de su algoritmo.
        \item $f$, es el máximo número de procesos defectuosos.
        \item Tenemos que definir como un proceso puede desviarse de su especificación.
      \end{itemize}
       En este último tenemos estas opciones: Falla de ruptura: falla en el que $p_{i}$
       se detiene prematuramente; Falla por omisión: $p_{i}$ no envía o recibe 
       mensajes; Falla Bizantina: Se comporta arbitrariamente.\\
       Estos fallos tienen una jerarquía por su severidad:\\
       Falla de ruptura $<$ Falla por omisión $<$ Falla Bizantina.\\
       Ahora, enunciaremos el problema del consenso con algunas variantes:\\
       El problema del consenso es que todos los procesos deciden algún valor que
       tenga coherencia. Esto está dicho en términos de las siguientes propiedades:\\
       \begin{itemize}
        \item { T - Terminación. Todo proceso correcto eventualmente decide. }
        \item { V - Validez. Si un proceso decide $v$, entonces $v$ fué propuesto. }
        \item { A - Acuerdo. Dos procesos correctos nunca deciden diferente. }
        \item { UA - Acuerdo Uniforme. Dos procesos, correctos o no, nunca deciden
        diferente. }
        \item { WV - Validez Débil. Si todos los procesos correctos propusieron
        el mismo valor $v$, entonces $v$ es decidido. }
      \end{itemize}
      Con esto tenemos tres tipos de problemas de concenso: El clásico (T + A + V)
      que se puede resolver, con fallas de ruptura y de omisión; el uniforme (T + UA + 
      V) que se puede resolver igual que el anterior y el débil (T + A + WV) que solo
      puede resolverse con fallas Bizantina.\\
      Para resolver el caso de falla por ruptura ocupamos una estrategia de conjuntos
      inundados sobre una secuencia de rondas. En cada ronda $r$: se envúa la nueva
      información obtenida durante la ronda anterior $r - 1$. El número de rondas
      que correrá es de $f + 1$ (note que cualquier cadena de $f + 1$ procesos incluye
      un proceso correcto).\\
      El algoritmo es fácil, simplemente se va llenando un vector con lo que ya se vió
      y al final todos verán lo mismo y pueden decidir el primer valor distinto de nulo
      que todos ven.\\
      Analizando la correctez del algoritmo:
      \begin{itemize}
        \item { Terminación. Se sigue de la sincronía en la ronda $f + 1$. }
        \item { Validez. Se sigue de que $\forall(i, k): V_{i}[k]$ es $v_{k}$ ó
        $\bot$. }
        \item { Acuerdo Uniforme. Hay que demostrar que si $p_{i}$ y $p_{j}$ deciden
        valores tales que $V_{i} = V_{j}$ al final de la ronda $f + 1$.\\
        Sea  $V_{i}[k] = v_{k} \neq \bot$. Así que $p_{i}$ ve a $v_{k}$ en alguna
        ronda $r$. Entonces $r$ tiene dos opciones:
        \begin{itemize}
          \item {$r < f + 1$: entonces $p_{i}$ envió $(v_{k}, k)$ a $p_{j}$ en
          la ronda $r + 1 \leqslant f + 1$. }
          \item {$r = f + 1$: de $p_{k}$ a $p_{i}$, el par $(v_{k}, k)$ llego a travéz
          de la cadena de $f + 1$ procesos, y al menos uno de ellos es correcto,
          digamos $p_{x}$. Ahora, $p_{x}$ obtiene $(v_{k}, k)$ en la ronda $r' < f + 1$
          y es enviado a $p_{j}$ en la ronda $r' + 1 \leqslant f + 1$.}
        \end{itemize}
        }
      \end{itemize}
      Analizando el costo: tiempo: $f + 1$, sea $b = nb$ el número de bits para
      codificar un valor: un par $(v_{i}, i)$ requiere $b + log_{2}n$ bits, un
      proceso puede mandar a lo más una vez a otros procesos, la complejidad de
      la comunicación entonces es de:\\
      $n^{2}(n - 1)(b + log_{2}n)$


    }
    
\end{enumerate}
\end{document}