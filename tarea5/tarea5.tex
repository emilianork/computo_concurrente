\documentclass{article}

\usepackage[utf8x]{inputenc}
\usepackage[spanish]{babel}
\usepackage[margin=3cm]{geometry}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{algorithmic}

\usepackage{ upgreek }

\usepackage{listings}

\linespread{1.2}

\title{ Computación Concurrente \\ \Large{Tarea 5}
\author{
  Diego Goméz Montesinos
  \and
  José Emiliano Cabrera Blancas
  }
\date{11 marzo 2014}
}
\begin{document}
\maketitle
\begin{enumerate}
  
\item{
    \textsl{
      Recuerden la platica de Borzoo sobre \textit{program
        repair}. Encuentra un algoritmo polinomial que repare la
      secuencia de estados, en el caso de una sola condición de
      progreso $\square$ (P $\Rightarrow$ $\triangle$Q), en donde hay
      un ciclo y sólo puedes quitar transiciones. Demuestra que es
      correcto y que es polinomial.\\
    }
 
    El algoritmo que Borzoo desarrolla es una heurística que abarca
    una clase de programas, esto es por que se sabe que el problema más
    general es NP-Completo. La entrada del algoritmo es la siguiente,
    la transicion de un programa con predicado $T_p$, un predicado
    invariante $I_p$, un conjunto de transiciones fallidas $F$ y un
    predicado de transicion malo $SPEC_{bt}$ y la salida a este
    algorítmo es un programa de transiciones con predicado $T_{p'}$
    con su predicado invariante $I_{p'}$.\\
    
\begin{lstlisting}[frame=single,mathescape,numbers=left,emph={repeat,until,return},emphstyle=\textbf]
ms := BWReachStates(Guard(F $\wedge$ $SPEC_{bt}$), F)
$I_{1}$, fte := $I_p$ - ms, false
mt := ($\langle$ms$\rangle$' $\vee$ $SPEC_{bt}$) $\wedge$ Group($\neg$ms)
repeat
   $I_2$ := $I_1$
   repeat
      $S_1$, $T_2$ := $I_1$, $T_1$
      repeat
         $S_2$ := $S_1$
         $S_1$ := FWReachStates($I_1$, $T_1$ $\vee$ F)
         $S_1$ := $S_1$ - fte
         mt := mt $\wedge$ $S_1$
         $T_1$ := $T_1$ - Group($T_1$ $\wedge$ mt)
      until ($S_1$ = $S_2$)
      ds := $S_1$ $\wedge$ $\neg$Guard($T_1$)
      $T_1$ := $T_1$ $\vee$ AddRecovery(ds,$I_1$, $S_1$, mt)
      ds := $S_1$ $\wedge$ $\neg$Guard($T_1$)
      $T_1$, fte :=  Eliminate(ds,$T_1$,$I_1$,$S_1$,$F$,false,false)
   until ($T_1$ = $T_2$)
   $T_1$, $I_1$ := ConstructInvariant($T_1$,$I_1$,fte)
until ($T_1$,$I_2$)
$I_{p'}$,$T_{p'}$ := $I_1$, $T_1$
return $I_{p'},$ $T_{p'}$
\end{lstlisting}

En la primera línea utilizamos la función $BWReachStates$ como una
caja negra(esta función fue tratada en otro trabajo y podemos decir
que su tiempo de procesamiento es polinomial), $BWReachStates$ sirve 
para obtener un $state$ $predicate$ donde las fallas por si solas
incurren en una violación al
predicado, de forma más explicita $Guard(F \wedge SPEC_{bt})$ son los
estados en donde directamente las fallas violan el $safety$ $predicate$
y la caja negra explora solamente hacia atrás buscando transiciones 
fallidas($FWReachStates$ funciona de forma parecida, buscando hacia
adelante en lugar de hacia atrás).\\
En la línea dos, como ya obtuvimos un predicado que nos obtiene estados
malos, entonces procedemos a retirar $ms$ para que nuestro programa de
salida sea tolerante a los fallos que hasta el momento hemos encontrado.\\
En la línea tres calculamos la variable $mt$ que son los predicados
que el programa que queremos hacer tolerante a fallos no debe ejecutar.\\
El primer $loop$ sirve para recalcular el predicado invariante, el
segundo sirve para recalcular el predicado de transición y el tercer y
último $loop$ recalcula el $fault$ $span$.\\
Necesitamos recalcular el $fault$ $span$ en cada iteración del segundo
$loop$ por que nuestro algoritmo añade y remueve transiciones que
originan los $fault$ $span$, por lo que nuevos estamos podrían ser
alcanzados y otros inalcanzables.\\
Es importante tener en claro que recalculamos el $fault$ $span$
comenzado una exploracion de los estados donde la invariante $I_1$ es
verdadera y aplicando las transiciones del predicado en la repesencia
de fallas(i.e $T_1$ $\wedge$ $F$) usando la funcion $FWReachStates$,
que previamente ya se habia comentado, $fte$ contiene las transiciones
malas previamente calculadas, por lo que procedemos a removerlas de
$S_1$.
Debemos notar que una condicion necesaria para que una transicion sea
no segura, es que su transicion origen sea un $fault$ $span$, en otro
caso la transicion puede existir en el predicado del programa tolerante
a fallos incluso si este se encuentre dentro de $SPEC_{bt}$ (linea 12).\\
Una vez que identificamos las transiciones no seguras, las quitamos
del predicado del programa (linea 13).\\
Ahora que hemos removido algunas transiciones se puede dar el caso en
donde se generen $deadlock$ que podemos componer de dos formas,
añadiendo un camino para recuperar la ejecucion del programa o
eliminando transiciones para que el $deadlock$ sea inalcanzable para
el programa. Estas dos operaciones se llevan acabo en las funciones
$AddRecovery$ y $Eliminate$.\\
La explicación de forma intuitva de como implementar $AddRecovery$ es
la siguiente: una vez detectado el $deadlock$ procedemos a crear una
nueva transicion que conecte el $deadlock$ con las transiciones
validas, si esta transición crea un ciclo en los estados, entonces no
se añade y se vuelve a buscar otra transicion que sea posible. Para
implemetar la busqueda de posibles ciclos nuevos, el autor Borzoo
incorpora el enfoque de Emerson y Lei.\\
El procedimiento para eliminar nuevos estados es, primero si ya todos
los estados $deadlock$ en $ds$ ya fueron considerados para eliminarse,
entonces $Elminate$ regresa los estados $deadlock$. Por otro lado si la
transición es alcanzable por una transicion fallida, entonces
regresamos al estado fuente del predicado y lo hacemos
inalcanzable. Esto es por que el programa no tiene ningun control
sobre cuando las fallas puede ocurrir.\\ 
Durante el proceso de eliminar los $deadlocks$ nos encontramos con que
algunas de esas transiciones pueden tener conflico con el predicado
invariate, marcando estas transiciones como $OffendingStates$.\\
Después de eliminar los $deadlocks$ procedemos a recalcular la
invariante con la función $ConstructInvariant$, esta funcion tiene
como proposito remover los estados del conjunto $OffendingStates$ del
predicado invariante y hacer esos estados inalcanzables.\\
Por último repitimos otra vez todos los pasos anteriores descritos hasta
terminar con la ejecución del programa.\\

Ahora que ya entendimos como funciona el algoritmo de Borzoo, podemos
utilizarlo para crear nuestro propio algoritmo para resolver el
problema dado.\\
La entrada del algoritmo es una secuencia de estados $T_p$ que
contiene un ciclo y una condición invariante $\square$ (P
$\Rightarrow$ $\triangle$Q).
La salida del algoritmo es la secuencia de estados $T_{p'}$ y una
condición invariante $\square$ (P$\Rightarrow$ $\triangle$Q).\\
El algoritmo es el siguiente:
\begin{enumerate}
  \item{Detecta la transición $s\rightarrow s'$, donde $s$ es el
      primer estado del ciclo.
    }
  \item{Elimina las transiciones que lleven a $s$, de tal forma que
      $s$ sea inalcanzable para cualquier ejecución del programa}

  \item{Regresa la secuencia de estados nuevo que se genero.} 
\end{enumerate}

Elminar las transiciones que lleven a $s$ claramente es polinomial,
por lo que la complejidad del algoritmo recae en encontrar la
transición $s \rightarrow s'$. Pero encontrar un ciclo en una grafica
dirigida se puede resolver en tiempo polinomial, por lo tanto el
algoritmo tiene complejidad polinomial.\\

El algoritmo es correcto por que al no generar nuevas transiciones el
predicado invariante nunca se ve afecto y al hacer inalcanzable el
$deadlock$, nos garantiza que no habra una ejecución de $T_{p'}$ que
caiga en el ciclo.
}

\item{
  \textsl{
        Explicar por qué el proble de encontrar un ciclo que pase por
        2 vértices dados es NP-Completo. (Solo dar un esbozo de la
        prueba)
      }
    }

  \item{
      \textsl{
        Recordemos ahora el modelo de memoría compartida wait-free y
        asíncrono para n procesos. El algoritmo que ejecutan los
        procesos en primera instancia fue:
      }
      \begin{lstlisting}[frame=single,mathescape]
Alg (id):
        r := -1
        view := id
   loop:
        r  := r+1
        mem[r] := write(view)
        $\upchi$ := scan(mem[r])
        view := conjunto de id's en $\upchi$
   until | view | = n-r
   output view
      \end{lstlisting}
      \textsl{
        Después vimos una modificación al algoritmo, en el cual un
        proceso ''no olvida'' si en una iteración anterior vio a algún
        otro proceso. Cambiamos el código de la siguiente manera:
      }
\begin{lstlisting}[frame=single,mathescape]
AlgNoOlvida (id):
        r := -1
        view := id
   loop:
        r  := r+1
        mem[r] := write(view)
        $\upchi$ := scan(mem[r])
        view := view $\cup$ id's en $\upchi$
   until | view | >= n-r
   output view
      \end{lstlisting}
      \textsl{
        Demuestra que los dos algoritmos son correctos y que cumplen
        la propiedad de que las vistas de los procesos están
        contenidas de acuerdo al orden en que los procesos terminan su
        iteración. (i.e. el proceso j terminó después que el proceso
        k, entonces la vista del proceso j esta contenida en la vista
        del proceso k.)\\
      }

      Por demostrar:\\
      Ambos algoritmos cumple con la siguiente propiedad:\\
      Las vistas de los procesos estan contenidas de acuerdo al orden
      en que los preceos termina su iteración.

      Demostración:

      Por contradicción sobre el algoritmo que olvida.\\
      Suponemos que existe un proceso $P_k$ que terminó después de que
      terminara el proceso $P_j$ ($P_j$ $<$ $P_k$)y la vista $view_k$ no esta contenida
      en la vista
      $view_j$, lo que implica que $\exists$ $P_i$ un proceso, tal que esta
      contenido en $view_k$ y no en $view_j$. Pero si $P_i$ no esta
      contenido en la vista $view_j$ quiere decir que el proceso $P_i$
      termino antes que $P_j$ y despues de $P_k$($P_k$ $<$ $P_i$ $<$
      $p_j$ ),
      pero eso querria
      decir que $P_j$ termino despues que $P_k$($P_k$ $<$ $P_j$).
      Lo cual es una
      contradicción a la hipotesis, por lo tanto si $P_k$ terminó
      después que el proceso $P_j$, entonces la vista $view_j$ esta
      contenida en la vista $view_k$\\
      Es claro ver que la demostración para este algoritmo funciona de
      igual forma para el algoritmo que no olvida, por que se sustenta
      en el hecho de que si un proceso no aparece dentro de la vista
      de otro, quiere decir que termino antes que él.\\
      Por lo tanto ambos algoritmos son correctos y cumplen con la
      propiedad antes descrita.
      
      
    }    
\end{enumerate}
\end{document}